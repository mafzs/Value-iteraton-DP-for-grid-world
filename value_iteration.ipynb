{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "value_iteration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sr7_1A3avXGm"
      },
      "outputs": [],
      "source": [
        "from __future__ import  print_function ,division\n",
        "from builtins import range\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating our environment"
      ],
      "metadata": {
        "id": "nYofEeLwp15e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_space=('u','d','l','r')\n",
        "class Grid :\n",
        "  #our environmetn\n",
        "\n",
        "  def __init__(self,rows,cols,start):\n",
        "    self.rows=rows\n",
        "    self.cols=cols\n",
        "    self.i=start[0]\n",
        "    self.j=start[1]\n",
        "\n",
        "  def set(self,rewards,actions):\n",
        "    self.rewards=rewards\n",
        "    self.actions=actions\n",
        "\n",
        "  def set_state(self,s):\n",
        "    self.i=s[0]\n",
        "    self.j=s[1]\n",
        "\n",
        "  def current_state(self):\n",
        "    return (self.i,self.j)\n",
        "\n",
        "  def is_terminal(self,s):\n",
        "    return s not in  self.actions\n",
        "\n",
        "  def get_next_state(self,s,a):\n",
        "\n",
        "    #setting the state\n",
        "    (i,j)=s[0],s[1]\n",
        "    if a in self.actions[(i,j)]:\n",
        "      if a=='u':\n",
        "        i-=1\n",
        "      if a=='d':\n",
        "        i+=1\n",
        "      if a=='r':\n",
        "        j+=1\n",
        "      if a=='l':\n",
        "        j-=1\n",
        "    return(i,j)\n",
        "  def all_states(self):\n",
        "    return set(self.actions.keys()) | set(self.rewards.keys())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U9mh2v-dzxV8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining rewards and actions"
      ],
      "metadata": {
        "id": "SHlelwjTp6Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_grid():\n",
        "  #. . . 1\n",
        "  #. x . -1\n",
        "  #s . . .\n",
        "  grid=Grid(3,4,(2,0))\n",
        "  rewards={(0,3):1,(1,3):-1}\n",
        "  actions={\n",
        "      (0,0):('d','r'),\n",
        "      (0,1):('l','r'),\n",
        "      (0,2):('l','d','r'),\n",
        "      (1,0):('u','d'),\n",
        "      (1,2):('u','d','r'),\n",
        "      (2,0):('u','r'),\n",
        "      (2,1):('l','r'),\n",
        "      (2,2):('l','r','u'),\n",
        "      (2,3):('l','u'),\n",
        "        }\n",
        "  grid.set(rewards,actions)\n",
        "  return grid\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6zBKPU1GcoZp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "two function just for displaying values and policy"
      ],
      "metadata": {
        "id": "XtjM5t-Ip9_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_values(V, g):\n",
        "    for i in range(g.rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(g.cols):\n",
        "            v = V.get((i, j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\")  \n",
        "        print(\"\")\n",
        "def print_policy(P,g):\n",
        "  for i in range(g.rows):\n",
        "    print('--------------------------------')\n",
        "    for j in range(g.cols):\n",
        "      a=P.get((i,j),\" \")\n",
        "      print(\" %s    |\" %a,end=\"\")\n",
        "    print(\"\")\n",
        "  \n",
        "\n",
        "      \n"
      ],
      "metadata": {
        "id": "GkJza_xuDnEt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating transition probablities and rewards"
      ],
      "metadata": {
        "id": "YYkxZYJfqPew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_probs={}\n",
        "rewards={}\n",
        "for row in range(grid.rows):\n",
        "  for col in range(grid.cols):\n",
        "    state=(row,col)\n",
        "    if not grid.is_terminal(state):\n",
        "      for action in action_space:\n",
        "        next_state=grid.get_next_state(state,action)\n",
        "        transition_probs[(state,action,next_state)]=1\n",
        "        if next_state in grid.rewards:\n",
        "          rewards[(state,action,next_state)]=grid.rewards[next_state]\n",
        "print(rewards)\n",
        "print('_____________________')\n",
        "print(transition_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l86FRo9JgfzZ",
        "outputId": "1158f62b-9381-49ff-fbbb-8a84d8e1641f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{((0, 2), 'r', (0, 3)): 1, ((1, 2), 'r', (1, 3)): -1, ((2, 3), 'u', (1, 3)): -1}\n",
            "_____________________\n",
            "{((0, 0), 'u', (0, 0)): 1, ((0, 0), 'd', (1, 0)): 1, ((0, 0), 'l', (0, 0)): 1, ((0, 0), 'r', (0, 1)): 1, ((0, 1), 'u', (0, 1)): 1, ((0, 1), 'd', (0, 1)): 1, ((0, 1), 'l', (0, 0)): 1, ((0, 1), 'r', (0, 2)): 1, ((0, 2), 'u', (0, 2)): 1, ((0, 2), 'd', (1, 2)): 1, ((0, 2), 'l', (0, 1)): 1, ((0, 2), 'r', (0, 3)): 1, ((1, 0), 'u', (0, 0)): 1, ((1, 0), 'd', (2, 0)): 1, ((1, 0), 'l', (1, 0)): 1, ((1, 0), 'r', (1, 0)): 1, ((1, 2), 'u', (0, 2)): 1, ((1, 2), 'd', (2, 2)): 1, ((1, 2), 'l', (1, 2)): 1, ((1, 2), 'r', (1, 3)): 1, ((2, 0), 'u', (1, 0)): 1, ((2, 0), 'd', (2, 0)): 1, ((2, 0), 'l', (2, 0)): 1, ((2, 0), 'r', (2, 1)): 1, ((2, 1), 'u', (2, 1)): 1, ((2, 1), 'd', (2, 1)): 1, ((2, 1), 'l', (2, 0)): 1, ((2, 1), 'r', (2, 2)): 1, ((2, 2), 'u', (1, 2)): 1, ((2, 2), 'd', (2, 2)): 1, ((2, 2), 'l', (2, 1)): 1, ((2, 2), 'r', (2, 3)): 1, ((2, 3), 'u', (1, 3)): 1, ((2, 3), 'd', (2, 3)): 1, ((2, 3), 'l', (2, 2)): 1, ((2, 3), 'r', (2, 3)): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Defining a policy evaluation function"
      ],
      "metadata": {
        "id": "QPZSuLUrqc1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_evaluation(grid,policy,V=None):\n",
        "  iteration=0\n",
        "  while True:\n",
        "    for state in grid.all_states():\n",
        "      if not grid.is_terminal(state):\n",
        "        new_v=0\n",
        "        for action in action_space:\n",
        "          for next_state in grid.all_states():\n",
        "            #deter,inistic policy\n",
        "            action_prob=1 if policy.get(state)==action else 0\n",
        "            r=rewards.get((state,action,next_state),0)\n",
        "            new_v+=action_prob*transition_probs.get((state,action,next_state),0)*(r+0.9*V[next_state])\n",
        "        V[state]=new_v\n",
        "    iteration=iteration+1\n",
        "    #print_values(V,grid)\n",
        "    print('\\n')\n",
        "    if iteration==25:\n",
        "      break\n",
        "    return V\n"
      ],
      "metadata": {
        "id": "HOKUyRQrj5RI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inintializing with random policy"
      ],
      "metadata": {
        "id": "o5NryFkbqhcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#starting with a random policy\n",
        "grid=standard_grid()\n",
        "policy={}\n",
        "for state in grid.actions.keys():\n",
        "  policy[state]=np.random.choice(action_space)\n",
        "print_policy(policy,grid)"
      ],
      "metadata": {
        "id": "1_YCF8tYj3Pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c684f0ca-4faf-4852-ce11-92de0469fb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            " r    | d    | r    |      |\n",
            "--------------------------------\n",
            " u    |      | l    |      |\n",
            "--------------------------------\n",
            " u    | r    | l    | u    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initializing all values with 0"
      ],
      "metadata": {
        "id": "HP_moj8oqoLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize V(s) = 0\n",
        "V = {}\n",
        "for s in grid.all_states():\n",
        "    V[s] = 0\n",
        "\n",
        "print_values(V, grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWtob7tKC_bq",
        "outputId": "3c61b5fd-2bb7-4fba-9c58-d90449ea3200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value itertion:we first perform evaluation just one time and we just use second loop of policy iteration approch, we perform value iteration until convergence\n"
      ],
      "metadata": {
        "id": "bVoSPJC1cxox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V=policy_evaluation(grid,policy,V)\n",
        "while True:\n",
        "  is_policy_converged = True\n",
        "  for state in grid.actions.keys():\n",
        "    best_value=float('-inf')\n",
        "    for action in action_space:\n",
        "      v=0\n",
        "      for next_state in grid.all_states():\n",
        "        r=rewards.get((state,action,next_state),0)\n",
        "        v+=transition_probs.get((state,action,next_state),0)*(r+0.9*V[next_state])\n",
        "      if v>best_value:\n",
        "        best_action=action\n",
        "        best_value=v\n",
        "    policy[state]=best_action\n",
        "    if best_action != policy[state]:\n",
        "            is_policy_converged = False\n",
        "  itteration+=1\n",
        "  if is_policy_converged:\n",
        "    break\n",
        "\n",
        "print_policy(policy, grid)\n",
        "print_values(V,grid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDy_4lFvEh4_",
        "outputId": "e97c8e50-8fce-4dc6-825c-3856f8b467a6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--------------------------------\n",
            " r    | r    | r    | g    |\n",
            "--------------------------------\n",
            " u    | x    | u    | h    |\n",
            "--------------------------------\n",
            " u    | r    | u    | l    |\n",
            "---------------------------\n",
            " 0.81| 0.90| 1.00| 0.00|\n",
            "---------------------------\n",
            " 0.73| 0.00| 0.90| 0.00|\n",
            "---------------------------\n",
            " 0.66| 0.73| 0.81| 0.73|\n"
          ]
        }
      ]
    }
  ]
}